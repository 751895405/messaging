

We envision a mix network using a sphinx-like packet format and loopix-like cover traffic, in which mix nodes are rewarded for participating.  We want some cover traffic to later be randomly selected in a lottery and deanonymized to provide a proof that nodes routed traffic correctly.  

We think selecting winning cover traffic packets should support strong anonymity properties, so long as those packets reveal nothing about users.  At the same time, we shall discover below that any control over winning cover traffic packets supports "malicious mining" in which packet creators bias rewards towards their own nodes.  We therefore design our protocol to reveal nothing about users, while requiring proofs that winning packets were constructed without biases, including biases produced by proof-of-work attacks.

# Design space

We first discuss the higher level aspects of the design space for such a protocol that do not depend overly on the cryptography.  We do currently assume a solid working knowledge of the mix network literature, at least for many motivational point, but may elaborate on the details later.

### Reward vs punishment

There are two possible outcomes to revealed packs, maybe a success results in rewards, or maybe rewards accrue in another way and failure results in punishment, or maybe both.  We think success should result in a reward because otherwise we need another system to distribute rewards with perhaps equally complex security concerns.  We do not yet know if penalties can be avoided, but we favor avoiding them if possible, if only for simplicity.  We think minor penalties like loss of rewards sound simpler than larger slashing-like penalties because avoiding staking makes participation easier and keeps the protocol simpler.  Also, slashing-like penalties complicates running nodes for competent people, who may lack wealth due to being cautious. 

There is however a "poor quality nodes" problem in networks like Tor and I2P, although I2P does not recognise it, in which poor quality nodes increase latency for the entire network.  We might not notice extras latency but we expect a similar "unreliable nodes" problem, and care about nodes' bandwidth, so users might benefit from established nodes for important roles like aggregation points, contact points, or even guards or other cross-over points.  We could represent reliability with stake directly, but we prefer to assess reliability directly, perhaps using stake from "reliability nominator" or "predictor" nodes who get slashed for poor enough behavior.  We might steal ideas for this from the availability game in polkadot.  In any case, we can leave assessing reliability as future work for after we have aggregation point code and applications that utilize it.

We therefore choose to reward based on successful packets for our immediate design goal, but leave assessing reliability to future work.

### Payment for only full routes vs partial routes

We shall pay only for payment packets that fully complete their route.  Importantly, this creates no anonymity problems because only cover traffic packets win the lottery and pay out.  

We could attempts to pay for good nodes in an initial segment of a partially completed route, but this creates many problems:  We think payments for partial routes is significantly more complex as discussed below under replay protection commitments.  Indeed we have not even fully answered the question of how one correctly identifies the node who dropped a packet and do not know if a solution exists.  If we have a stratified topology, then partial routes are unfair to good nodes who appear later in the topology, which creates nasty political problems.  Also, cycling the topology frequently would fiber the anonymity set.

### Relay vs user generated cover traffic

There is cover traffic generated by both relays and users in Loopix, so reward generating conver traffic could come from either or both.  Ideally both sounds best, but more complex. 

Relay generated cover traffic comes from all relays in Loopix, not just guard nodes or aggregation points for us.  We can enforce that nodes generated traffic correctly by threatening to void their rewards.  We do not envision slashing because we do not envision all nodes being staked.  We have no similar threats against users, well not unless they pay or get paid too, but if most traffic is user generated then we may encounter other reasons for preferring user generated cover traffic.

As a counterpoint, we worry that if only relays generate cover traffic then running bad virtual nodes that generate cover traffic and censor users becomes highly profitable.  We could stake and slash such nodes, but doing so fairly sounds hard, worse than the availability game.

We shall revisit this point soon after considering further design criteria, especially the route selection section below, but all cover traffic being eligible for the lottery sounds preferable, even if we do not implement that initially.  

### Social vs. cryptographic solutions

We shall discuss cryptographic approaches to route selection bias below.  If route selection were solved, then it's plausible that running more nodes is always the optimal strategy for small players, but large enough players eventually benefit from running machines that spam cover traffic.  In this model without route selection bias, any player spamming honest traffic should still benefit from more real users, so that they could spend money running nodes instead of fake users. 

In reality however, we cannot completely solve route selection because an adversary with enough nodes and enough fake users producing candidate routes could always choose not to expose routes unless they themselves win.  We might address this by making the winning traffic cover packets publicly verifiable somehow, which requires keeping winners off the queues that contain real messages, or more likely off users entirely.

There is a separate problem that any sufficiently large operator inherently compromises the network's anonymity goals.  Indeed, some adversaries would do this for reasons besides financial rewards.  

We believe this could only really be addressed by encouraging human interactions between relay operators, which deanonymize relay operators to one another and permit assessment of unusual behavior.  These human interactions might help determine layers in a stratified network topology with relay operators who could vouch for one another landing in the same layer and ideally monopolising entire layers, so that such adversaries never see packets entire routes. 

We note that Katzenpost currently takes an even more dramatically human centered approach by requiring that all nodes belong to quasi-activist organisations.  These organisations charge users for network access, or raise funds other ways, store their own users messages, and handle abuse manually.  We dislike this strategy because it prevents casual participation, does not provide many useful properties like per-user DoS protection, does not provide a distributed service, and imposes considerable complexity on operators.

We nevertheless believe that human social relationship must be prioritised over cryptographic solutions for route selection, etc., perhaps even the easy solutions based on Intel SGX and Arm TrustZone, because ultimately those relationships defend the anonymity.  We could perhaps develop an endorsement scheme among node operators, or key signing parties, but use a stratified topology with restricted routes that (a) minimizes packets forwarded between friendly nodes and (b) isolates all nodes not participating in endorsements into one or two layers.

We do expect automated route selection to increase in importance to counter financial missbehavior though.


# Reward protocol

We imagine some user Alice has constructed a sphinx packet header with curve point P_i at hope R_i and that some fragment of the packet's path looks like
  .. -> R_0 - R_1 -> R_2 -> R_3 -> ..

## Relay replay commitments

We worry that Alice need not actually send her packet but merely generate it and then sometimes create payments without anyone doing any work.  Arguably this sounds non-problematic if Alice spends money, but without that assumption it sounds problematic.  We therefore make nodes commit to the packets they process before holding the lottery.

### Delivery receipts  

Associated to P_i at R_i, we define a 128 bit value that R_{i+1} computes and sends back to R_i given by
  delivery_receipt = H(KEX(P,R_{i+1}) ++ "Reward Auth Out")
We could then shield delivery_receipt from R_{i+1} if R_i computes another value
  safer_delivery_receipt = AES(kex_dr, reward_auth_back)
where
  kex_dr = H(KEX(P,R_i) ++ "Delivery Receipt Safety")
If we were not using probabilistic payments, then Alice could encrypt a payment to R_i using delivery_receipt or R_{i-1} could do so using safer_delivery_receipt.

We recall that sphinx requires mix nodes store replay protection databases, which must live as long as packet headers, including SURBs.  We envision the payment protocol requiring that nodes produce some commitment to their replay protection database, and reveal secret information from those commitments.  So our replay protection records have the form (replay_hash, ...) where
  replay_hash = H(KEX(P,R_i) ++ "Replay Protection")
and ... is whatever secret information we require. 

We could store delivery_receipt or safer_delivery_receipt in this secret information, which R_i could learn only from the subsequent hop R_{i+1} or Alice.  If we store only this, then a packet appearing to die at hop R_{i+1} could mean R_{i+1} dropped the packet, or R_i and Alice together forged the record from R_{i+1}.  This seems okay if we only pay only for full successful routes because R_{i+1} must sign their own commit and reveal messages anyways.  

It's plausible R_{i+1} might do so falsely for profit, but we could add some outright fake queries that resulted in penalties.  We might prevent false accusations by ensuring the fake queries were generated later than the traffic.  If done correctly, this certainty permits quite severe penalties, although currently we do not expect that ordinary nodes have stake. 

### Deniability vs signatures

We could help support partial routes if R_i stores a signature provided by R_{i+1} 
  reward_sig = S(R_{i+1}, delivery_receipt)
If R_i signed his commitment to his replay protection database, then this signature proves that either the packet was forwarded or else that R_i and R_{i+1} colluded, avoiding the collusion between Alice and R_i case.  There are two issues with using a signature here:

First, if we do even a simple Schnorr signature here, then nodes must compute an extra public key operation r = g^k used in the signature.  R_{i+1} cannot improve performance by using r repeatedly so long as R_i sees and verifies the signature.  If R_{i+1} only commits to a signature, then conceivably R_{i+1} could delete some vital information when claiming a packet, thus preventing two signatures by the same r being exposed, so maybe r can be reused for dramatic computations savings.  We might want to prevent claiming too many packets in this way, but it makes the system fragile when relays restart, etc.

Second, we fear storing signatures stores evidence about all packet's routes.  In principle, we achieve some deniability here if we define k = H(sk_{i+1} ++ P_{i+1}) and r = k P_{i+1} and store only s = k - sk_{i+1} H(r ++ M) but immediately delete r rather than storing it with the signature.  In payment, r can be recomputed by R_{i+1} only after Alice reveals P_i and signature can then be verified as usual, but this sounds like several more protocol moves.  We might still report r to R_i to verify the signature.  R_i knows P_{i+1} but deletes it.

## Route selection for cover traffic

We want running nodes to always be the most economical method to acquire tokens.  In particular, we want nodes to generate their cover traffic honestly, neither biasing the route, nor sending excess cover traffic.  At the extreme, we're happy with proof-of-useful-work, perhaps best named proof-of-onion here.  We must not degenerate into proof-of-useless-work, ala bitcoin however. 

We face a hurdle that cover traffic senders could bias their cover traffic towards their own nodes, thereby favouring themselves when their own cover traffic packets win the lottery.

At first blush, there is a relatively straightforward sounding scheme for route selection, given some strong assumptions on timing and consensus:  We consider some node Alice that generates cover traffic eligible to win the lottery.  Alice has a VRF key v to which she is committed.  Alice seeds her VRF with some representative for the current time to produce a verifiable CSPRNG, probably by using the output to seed ChaCha20.  Alice uses this CSPRNG to sample her route from the network consensus.  

We discuss several complications here and propose solutions.  These solutions have notable code complexity overhead, but they only arise when Alice's cover packet wins the payment lottery, giving them acceptable performance even for slow solutions.  We suggest initially addressing these concerns with three dirty Intel SGX and Arm TrustZone hacks, and requiring that users clocks not be too skewed, but even this could wait until the network sees significant adoption.

### Alice should be uniquely committed to her VRF key 

We cannot ask that intermediate relays verify Alice's VRF key when forwarding packets because they have trouble verifying many properties, like say uniqueness.  Also, the VRF key lives in a pairing based curve, which hurts performance if evaluated everywhere.  

Imagine first that relays generate the cover traffic from which we create payments.  A relay Alice could run multiple virtual relays to obtain more VRF keys.  All nodes generate cover traffic in Loopix.  We could however employ stake here if either (a) not all relays need to generate cover loops or (b) all nodes were stakes.  Alice could still run numerous minimally staked relays, so winning musst be tied to stake in this scenario.  We could evaluate if merely loosing of reward provides sufficient economic incentives when all relays generate cover traffic but not all relays are stakes.  If not, we'd need more complex solutions designed for users.  

Imagine second that users generate cover traffic.  An honest guard could enforce that a user Alice commits to her VRF key, but what comes first the guard selection or the VRF key commitment?  Alice could run her own guard or connect to many guards, if either gave her more VRF keys.  There are practical issues with Alice's VRF selecting her guard, like guards being down, so the route selection solution might not work at guards anyways.  I'd expect this creates hiccups in using a stratified topology with restricted routes.  We might simply publish user's IP addresses when their cover traffic wins, but this likely creates privacy problems. 

We could certify Alice's VRF key from another node using a blind signed certificate, except naively that node could issue an unlimited number of blind certificates.  We could employ a threshold blind signed certificate though.  I dislike the complexity here but if Alice is expected to pay for services, then a threshold blind signed certificate provides a convenient avenue for that payment.  We could even produce a zero-knowledge proof that she burned money on chain and exploit an existing threshold blind signature by validators.  We might certify Alice's VRF key using other unique resources like a phone number, again incurring complexity from threshold blind signed certificates.  

In fact, our easiest solution would likely be to certify VRF keys using the machine itself as a unique resource, via Intel SGX and Arm TrustZone.  These lack strong threat models but they suffice for preventing malicious mining.  If we run the VRF outside the trust boundary, then Alice could employ malware to mint VRF keys, but she could equally well create numerous phone number registrations with Android malware. 

### Alice should sample the full consensus 

If Alice has the full consensus, with weightings by node capacity and reliability eventually, then she could sample it using her VRF easily.  We expect this to be the case if only relays generate cover traffic that wins.

We know the consensus eventually becomes the scaling bottle neck for any anonymity systems, which bodes poorly for users naively generating cover traffic that results in payments.  Right now, Tor is already stretching their consensus by distributing the full list of 6000 nodes to 2 million users.  We might distribute more frequently since relays' keys rotate.

There is a larger research project around doing partial consensus information securely, or using gossiped node details, but if we have a partial consensus scheme then we can sample it securely using a VRF, albeit with considerable complexity.  Alice commits to her view of the consensus when she (re)registers her VRF key, which permits her learning about more nodes, but sadly prevents her from including them into her consensus sampling pool quickly.  Alice now produces zkSNARKs proving that she looked up each node correctly.

We should worry that this slow start to the consensus creates problems for new nodes.  Also these zkSNARKs create painful complexity, but their performance looks okay since they only happen when winning the lottery.  

Again, we should consider using Intel SGX and Arm TrustZone, as doing so matches the above commitment security model, but now we must process more data, which sounds problematic for these technologies.  All this could wait until we hit 10k nodes regardless. 

### Alice feeds her VRF a network friendly time 

We do not want Alice to spam cover traffic by sampling her VRF across a massive number of time slots either, so the times with which she seeds her VRF must be constrained.  We thus expect nodes validating the lottery winning packets should reject excessive clock skew or otherwise constrain the allowing timing for Alice's packets.  

We must first worry about large scale issues that impact what goes into Alice's VRF:  We could use recent block heights here, except Alice is likely to be an extremely lite client, maybe even if Alice were a guard or aggregation point.  There is a case for keeping any chain somewhat distant, ala Whisper, but our replay protection commitments from relays likely requires some chain presence, so maybe relays can learn block heights.  We have discussed network timing information for polkadot's block production, etc. too.  There are designs that give us signed messages with time information from different nodes, which sounds more amenable if users cover traffic wins the lottery.

### Alice must evaluate her VRF sparingly

We should probably require that Alice seed her VRF only with rough time to further limit her time slots. 

In Loopix, all traffic categories are exponentially distributed \Exp(\lambda), normally using ziggurat tables, including traffic originating from both user and relays.  We observe that a VRF producing winning output by VRF(momentary_seed) < x is already exponentially distributed.  It's too much computation to run a VRF say every second on a mobile device though, so honest users cannot do this and only attackers do.  

We could stretch one VRF output into many infrequently verified VRF outputs by sampling a real VRF once or infrequently and seeding a CSPRNG like ChaCha20.  In principle, this gives random number outputs with similar properties, including verifiability and independence as far as probabilistic polynomial time adversaries see (TODO: cite old/original VRF paper).  

In stretching our VRF, we must not reveal the original VRF output since we do not want to reveal anything about other time slots, possibly including real messages depending upon the cover traffic strategy.  Instead, Alice reveals a lottery winner by producing a zero-knowledge proof that her exponentially distributed samples were computed correctly from the original VRF with her key, but now without revealing that actual VRF output.  We might use a simple DLEQ proof that require only a couple curve points, since Alice's VRF is merely a BLS signature.  See:  
  https://blog.cloudflare.com/privacy-pass-the-math/
  https://github.com/privacypass/challenge-bypass-server/blob/master/crypto/dleq.go
  https://github.com/privacypass/challenge-bypass-extension/blob/master/scripts/crypto.js#L295
It's much harder to prove the stream cipher output is correct, although zkSNARKs and bulletproofs sound plausible here, and maybe even witness indistinguishability proofs like ZAPS work.  We may keep separate the DLEQ proof and stream cipher proof by sharing only a commitment between them.

We might ask if our stream cipher output could be optimised for doing the zero-knowlege proofs, while retaining independence, security, etc.  If we only want to evaluate the VRF once every m time units, so that i < m, then we might try 
  VRF_i(epoch_seed) = H( sk_A H_1(epoch_seed) + sk_A H_1(i) )
We reveal the aggregated signature sk_A ( H_1(epoch_seed) + H_1(i) ), and epoch_seed and i are known, so we require only a signature verification, not a DLEQ proof.  Importantly, we must argue that this hides the non-aggregated signatures sk_A H_1(epoch_seed) and sk_A H_1(i), as otherwise an adversary could collect sk_A H_1(i) terms to determine non winning packet timings.  

Some heavier zero-knowledge techniques have post quantum blinding, which makes our VRF post-quantum if the certificate is blinded too, but not this simple signature based scheme.  Also, there is a considerable precompute required to produce sk_A H_1(i) for i < m, while heavier zero-knowlege techniques incur serious computational overhead only when their packets win.

In this vein, these are roughly verifiable pseudo-random sequence generators (VPRGs) described in section 5.2 on page 19 of this ZAPS paper:  http://www.wisdom.weizmann.ac.il/~naor/PAPERS/zap.pdf
There are also ideas inspired by hash based signatures as well, like committing to f(m) pairs of 128 bit numbers x[j][b] for j < f(m) and b=0,1 and using the "stream cipher" given by
  H(x[0][bs[0]] ++ .. x[m-1][bs[m-1]] ++ bs) where bs = H(sk_A G_2 ++ i)
but this also requires considerable precomputation since naively f(m) is exponential in m.

I suppose Intel SGX and Arm TrustZone might prove useful here too.

As an aside, adding up all Alice's previous samples gives an Erlang(n,\lambda) distribution.  We know 
  \Exp(\lambda)  ~  {-1 \over \lambda} \ln U  and
  \Erlang(n,\lambda)  ~  {-1 \over \lambda} \ln \Pi_i^n U_i
where U_i are uniform on the open unit interval (0,1).  If we could obtain these U_i directly as the output of a multiplicatively homomorphic VRF then we could maybe prove this efficiently, but this sounds hard and it must still begin somewhere.  


## Winning the cover traffic lottery

We should select cover traffic packets that win the lottery by first producing some collaborative random number with which all eligible cover traffic producers like Alice hash each cover traffic packet header.  If these score low enough then that packet pays out.  We do include the route information when hashing, but we build packets from a PRNG so it suffices to include only the initial seed of the PRNG not the full packet header.  

As discussed above, we want to seed this PRNG with a stretched VRF denoted VRF_i(epoch_seed) where epoch_seed is some well determined previous collaborative random number.
  H(collaborative_random ++ VRF_i(epoch_seed)) < epsilon.  
We ensure VRF keys are selected well in advance of the collaborative random number, so that packets cannot be maliciously mined by merely choosing VRF, aka reduced to proof-of-work.

We mentioned earlier that selecting winning cover traffic packets should strong anonymity properties, so long as those packets reveal nothing about users.  

As a further justification, we observe that Loopix substitutes real packets into one stream of cover traffic.  We need not take winners from this stream, even if we do choose winners from users, but if we do take packets from this stream, then users must skip revealing any real packets.  We believe incorporating VRF output for winning packets reveals nothing about other packets, maybe thanks only to computational Diffie-Hellman assumptions, but VRFs seemingly require more complex assumptions.  We think skipping packets make the scheme more sounds more friendly to users going offline too. 


